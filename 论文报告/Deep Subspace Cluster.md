# [Deep Subspace Clustering Networks](http://papers.nips.cc/paper/6608-deep-subspace-clustering-network)

这篇论文主要是提供了一个思路，就是如何利用自动编码器进行聚类。当然一般的想法我们可以直接训练一个自动编码器进行聚类，然后对聚类的特征我们可以采用密度聚类等等特点来进行聚类尝试。这篇论文提出的方法是可以采用自表示方法+谱聚类进行聚类，效果不错。

[TOC]

## Outline

本文要从以下几个角度来对文章**Deep Subspace Clustering Networks**进行探讨，并探究这个文章有什么样的精髓特征。

### 这篇文章是属于哪个领域的文章

### 这篇文章解决了什么样的问题，这种手段有什么用

### 这篇文章有什么不足的地方，要实现它有什么样的手段

## 这篇文章是属于哪个领域的文章

这篇文章属于子空间聚类的文章。什么是子空间聚类呢？子空间聚类就是把图像之间的关系用一个矩阵来表达出来，然后对这个矩阵采用谱聚类等方面进行聚类。简单来说就是把需要聚类的物体之间的关系用矩阵刻画出来（相当于把关系映射到了低维空间）然后对这个关系矩阵进行聚类就可以了。

在聚类方法确定的情况下，如何构造关系矩阵就是一个非常重要的问题了。这篇文章构建关系矩阵的行为是**self-expression**方法，简单地来说，就是把一个数据写成其它数据的线性表达，然后用这个线性表达来聚类。

## 这篇文章解决了什么样的问题，这种手段有什么用

对图像之间计算线性表达是一件非常困难的事情。首先不好优化，其次这个线性表达似乎没有什么道理在里面。因此文中提出我们应该使用深度编码解码器，然后对编码的向量作为数据的代表进行线性表达。假设我们的编码向量为Z，那么线性表达就是$||Z-ZC||$。我们在编码器中间加一个矩阵C，将$ZC$送入解码器要求满足$||Z-ZC||+||X-decode(ZC)||$尽量小，同时要满足C是一个对角元为0的矩阵。因此本文的主要手段就是用深度学习去训练这样一个矩阵C。

本文的策略就是先预训练一个完全的，可以的，ok的，良好的编码器，然后加上C，采用损失函数
$$
L(\Theta,C)=1/2||X-\hat{X}_{\Theta}||^2_F+\lambda_1||C||_P+\lambda_2/2||Z_{\Theta_c}-Z_{\Theta_c}C||+\lambda_3*sum(diag(C)^2)
$$
来进行训练，最后得到一个能够拟合高层特征的编码器

## 这篇文章有什么不足的地方，需要哪些手段来实现

我个人觉得这篇文章的问题在于第一网络不能做的特别深，这就导致扩展复杂度不够。第二在于这个网络对于C是线性限制，相当于是其它向量的加，这个我就觉得非常有趣。为什么对于编码结果线性表达就可以了呢？为什么不能是乘呢？整个输入的过程就不是线性的为什么最后就可以线性了呢？这里面需不需要加一些非线性项比如交叉乘，或者向量归一化等等的呢？假设深层特征可以进行线性化表达，这个假设的理由在哪里呢？这些都是未知的手段。就我而言用密度可能更好。

然后还有一些问题是调参的问题。总觉得调参调不好。

最后我用子网络特征输入输出来解决了第一网络不能做的特别深的问题。这个思想是可以推广的，说不定有什么希望在。

总之一切需要实验来说话。