# 工作总结

昨天临走之前我将神经网络增加了1个block做了一个测试，然后用了BinaryLoss与求和来进行整个网络的训练，整个网络的loss下降得很快，而且用了官方的Binary Loss后也没有了数值loss=nan的问题，但是仍然会出现泛化能力不好的问题。

泛化能力是必须要解决的能力，如何增加它的泛化能力是一个非常关键的问题。

再说吧。

## 一个巨大的问题

例子上的结节都是横向排列的，我们的cube都是纵向排列的。这应该是输出visual看一看的时候发现的问题。

## 可视化过程

记录原图，看看原图的问题。

