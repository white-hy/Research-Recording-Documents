# 训练结果

## 最终我们的Dice是只达到了0.67左右，而同时相应的Precision也提高了不是很多

事实上在这个问题上我发现就算是用完整的U-Net进行训练，其Dice也就在0.7上下波动，因此是不是整个系统有问题呢？

考虑原来的系统：

![1528676777407](C:\Users\JIAZHE~1\AppData\Local\Temp\1528676777407.png)

我认为这个系统有一些语焉不详，因此我所复刻的是在这个基础上增加的。因此这个系统是有自己的一些问题。

我的复刻系统如下所示：

![1528678458379](C:\Users\JIAZHE~1\AppData\Local\Temp\1528678458379.png)

这个系统是基于一个U-Net和一个分类网络所实现的，它接受如图所示的输入，并进行分割与良恶性判断。它所用于训练的网络参数是在200步的时候学习率衰减一次，变为原来的0.1。

我们的损失图表示，在200步的时候Dice有一个飞跃性的上升，但是于此同时Test的Precision反而在下降了。这就表示非常疑惑，也就是说这里其实在预测方面结果一直在震荡。

满足两个任务还是有些难的。

修正：

1. 不加学习率衰减到400步，再衰减一次跑200步
2. 看一下train数据集的dice和voe的结果
3. 看一下test,val数据集上的结果

修正结果：

1. 分类精度在训练数据集上达到了几乎100%，这个是非常让人惊讶的。当然还是有一些数据训练起来有问题，也就是说我们没有增加focal机制，使得有一些数据得不到充分训练
2. 训练集的Dice也并没有达到很高的结果。用Dice作为损失函数似乎不是那么舒服，或者说它还需要很久时间去训练，我们需要把时间放更久一些。
3. 在400步的时候测试集精度会遇到严重过拟合，验证集也是的。它们都会飞速下降，这里也是一个问题

下一次训练需要注意的：

1.加入focal loss机制

2.加入Dropout以防范过拟合

3.增加Data Augmentation?

## 训练总结

昨天我增加了基于Dice的权重增加与基于Precision的Focal Loss，起到了一些比较好的结果。现在整个网络的Precision值得到了很大的提升，在Test上达到了0.93，Val上有0.90，但是还是没有达到原文献中的结果。

注意到原文献的结果是

![1528864951995](C:\Users\JIAZHE~1\AppData\Local\Temp\1528864951995.png)

因此我们的结果仍然还未达到。

我们现在结果大概达到了66的Dice,92的Accuracy，我很怀疑论文上这个结果是怎么来的。可能需要对网络结构进行修正吧。

等这次跑完我们再改改看

仍然不行，在600步的时候precision会降低，而dice会增加。看来Joint会有问题。

## 6.14日训练结果

在我们对权重进行了改变之后，我们发现dice下降了，precision上升了。也就是说我们的神经网络主攻precision而放弃了dice，这是一个很奇怪的事情。

我觉得有必要做的是首先平衡权重，其次选dice这个loss可能并不是很好，我考虑把它修改成其它loss

## 6.15日训练总结

采用交叉熵作为loss后在分割部分果然让分割结果得到了一定的提升，但是问题在于整个结果仍然没有达到一个很好的地步。

结果：

在200步前面的时候，整个网络呈现一种Dice急速下降的态势，而后来加入cls loss之后Dice就不再上升了，反而下降了，而precision在上升，这里是有一点疑惑在。

## 6.16日训练总结

模型呈现这样一种态势，就是说分割与分类好像处于一种不能同时去完成的这样一种状态。按原论文的理论而言，分割信息是可以辅助分类的，但是在这里并没有起到辅助分类的作用。似乎模型的拟合能力是有限的一样，要么给分割，要么给分类，这样就很糟糕的样子，即模型并没有把特征进行充分的融合，面对这种情况，我们应该怎么办呢？

1. 首先尝试你就只用分割，看看能获得什么样的效果
2. 其次写一套代码，试着先分割，然后微调训练分类

直接训练分割是有问题的，它的Dice损失也上不去，不知道为什么，我总觉得这个方法比原来的方法还差了。

实在不行就考虑原来的网络，用这种方法进行分割试试。

（似乎原来的网络也不行，就是说这个数据集本身就是很难去分割出来的？）

查一下数据生成过程的问题。





 

