# Task 4.3

## 一个关于正则化项的教训

正则化项设置得太大（从0.001到0.01）就会导致训练最后结果不好。这种结果不好可能是指比如最后只能达到0.7的VoE了等等。

重点还是对抗训练部分。

## 对抗训练部分

我现在拥有的数据集是一个来自上海肺科医院的数据集，它有对结节的位置信息的标注，也就是和原来的数据集很像。我可以尝试用它来进行对抗训练。

## 学习率衰减参数设置

我这几天发现了一个非常重要的学习率衰减策略，叫做通过预训练衰减学习率的策略。学习率衰减是非常重要的，就算是Adam也是非常重要的。（虽然Adam是自适应学习率方法，但是这些方法也是非常重要的方法）。

一般我们如何确定学习率的衰减参数呢？一般来说我们可以先第一次训练一个不衰减的网络，看看网络哪一步平稳了，然后第二次训练的时候就在这里衰减学习率。一般初始学习率可以设置为1e-3，设置3个衰减节点之后达到的最优值就是当然的最优值了。

## 论文阅读

论文中cluster 一文给我很大的启发，我可以试试3D的改装。

## 看一看Adversarial策略对Batchsize的限制

注意到用了Adversarial后似乎训练的这个分类器其实很难判别了,我总觉得这个分类器有一点问题就是它并没有和Segnet一起成长，也就是说它很难学到我们想让它学的这个策略，这就导致了这个对抗策略没什么用。

## 对Segnet再多做一些改动吧

我这次对Segnet做了经典的concat操作，以期望能从concate操作中获取一些更好的结果。

学习率设置得太低就没用了，所以我这次使用0.5的学习率衰减函数

## 关于用Deep Learning 做聚类

我觉得那个中间的很难弄，毕竟1000多张图片可能跑不起来。

## 其它的一些想法

明天早上先把关于自动编码器的几篇文章找到改一下，看看能不能直接用。然后再看看做了特征concate之后的结果怎么样，能不能让人满意再做打算。

我总觉得还是要先编码再做决定，反正已经有了一个成熟的网络了。



