# 训练报告与可行的解决思路

## 加深神经网络效果

1. 验证集的Error确实下降了
2. 出现了一个Loss = Nan的小问题

## 可行解决方案

注意到训练集loss一直下降，验证集loss平稳反增有2个可能性：

如果验证集loss反增的这个底线比较大（比如训练loss可以下降到0.08左右，而验证loss只能达到0.55就反弹了），那么可能是模型拟合能力不足导致的过拟合，可以通过增加Dense Block的数目来试着缓解，而事实上确实缓解了这些问题。

如果验证loss反增的底线较小，那可能确实是过拟合了，需要一些其它的手段。

Nan的原因可以试着用Cross Entropy来解决

## 做的任务

1. 尽量先把Block做的非常深，比如我可以做6个block先训练看看
2. 把loss的问题先解决，看看这次是因为梯度爆炸还是因为自己的Loss问题，看看能不能复现
3. 做一下Data Argumentation试试
4. 把Github上的Densenet efficient学会并用在自己的网络中。

## Danny Chen的建议

CVPR,ICCV,ICPR



Github: Densenet efficient:

(GPU占用量低，速度快)

12个growth rate one block

## Tips

```
 BCELoss(size_average=False)
```

这里确实会输出 torch.sum不是mean的值

## Professor Chen's Suggestions

1. 工作可能会有竞争

2. 一个工作还没有做的：分割出来之后需要估计效果好不好。Suggest是评估分割效果的。评估分割效果在各个上都存在，现在的做法是让专家看好不好。让专家看，怎样给专家看。一个思路是做一个评估分割结果的模型。这是一个更加广泛的东西。评估效果，给专家只看一些地方就可以了。用GAN来做。本质就是只看一些部分，让系统自己去看。（增加注意点？）

   AD模型就是批评模型的作用，告诉这里分割做的不好，如何提高等等。

   自动提高的过程。

   让系统自己去找到哪里分割不好

   找两个模型，第一个模型进行分割，第二个模型告诉第一个模型哪里分割不好，然后告诉第一个模型，第一个模型在这些位置做注意力。

3. 思路类似，技术上的要求也会高一些