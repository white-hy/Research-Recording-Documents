# 科研进度与所遇到的问题

[TOC]

## 科研课题

1. 3D语义分割问题与对抗策略

   考虑用对抗网络来对所产生的结果进行批评，从而通过批评策略增加优化分割结果，或者通过批评策略精确定位是哪个局部区域产生了不好的结果，并对这个局部区域进行推荐标注优化（局部推荐标注策略）

2. 特征聚类算法与推荐标注策略

   尝试对未标注数据进行聚类，利用聚类结果来尝试直接用一步来做推荐标注系统

以上两个课题我都是以3D的肺结节分割问题作为研究的实例的。我把LIDC数据集的肺结节标注做了处理（包括对重复标注结节的聚类，以及对医生边界标注填充和边界腐蚀，体素归一化等），选取了2个及以上医生标注过的结节构建了一个含1148个结节和对应的分割标注以及在原图上的Bounding Box坐标的数据集进行研究。

数据集就像这样：

![dataset](C:\Users\Jiazhe Love Junjun\Desktop\Research-Recording-Documents\讨论\dataset.png)

这个数据集比较方便做3D语义分割或者是3D Object Detection相关的实验。

## 现有成果与困境

### 利用**Densenet**做出了一个性质良好的分割网络

![1523934925783](C:\Users\Jiazhe Love Junjun\Desktop\Research-Recording-Documents\讨论\denseconnection.png)

它是一个只需要3000MB的轻量级网络，收敛速度快(大概训练5小时即可收敛)，最终结果和现在的3D U-Net的结果一致。与3D U-Net相比，它所耗内存是U-Net的一半，收敛时间也是3D U-Net的一半，但是结果可以与U-Net相媲美，应该算是一个分割网络的改进。因为这个网络占用内存小，可以同时跑多个，并可以快速对结果进行验证，所以我的实验都选择这个网络进行。

3D U-Net的分割结果能够达到平均$Dice:0.763,VoE:0.37$，而Densenet能够达到平均$Dice:0.757，VoE:0.373$，两个网络结果基本等同。

### 尝试了论文**Deep Adversarial Networks for Biomedical Image Segmentation Utilizing Unannotated Images**的训练策略。

考虑到3D语义分割与对抗策略这个课题，以及我也是才开始接触对抗策略，没有什么思路，然后我就想先尝试把这个论文的策略在我的数据集上复现一下。

我是用与上面的Densenet相似的结构构建的Adversarial Net的结构，未标注的数据集我选用的是上海肺科医院的数据集，因为这个数据集只给出了结节的中心坐标，没有给出Bounding Box或者是精细分割标注，而且独立于LIDC数据集。但是它有额外的标注是关于每个结节的分类(原位腺癌，浸润腺癌)，我想可能这个信息也可以想办法用在对抗策略中。因此我用LIDC的数据集作为有标注的数据集，上海肺科医院的数据集作为无标注数据集，采用论文中的策略对我的数据集进行了训练。

训练的结果是整个训练过程中所用的trick很多，比如如果一开始分割网络训练的步数太多，那么就会导致批评网络没办法得出很好的批评结果，这里的超参数，以及交替训练的策略步数需要很多次实验然后确定。同时这里的对抗策略并没有如预期一般对网络最后的结果与泛化性有提升。

我对比了LIDC与上海肺科医院数据集的结果，发现一个可能的原因。LIDC的数据集里面有各种形态的肺结节，但是它里面如下图所示的毛玻璃形态的结节数目非常少：

![unannotated](C:\Users\Jiazhe Love Junjun\Desktop\Research-Recording-Documents\讨论\unannotated.png)



我提出的一个**可能的猜想**是可能肺科医院的肺结节的形态特征的概率分布与LIDC是不一样的，也就是说我用这个数据集进行对抗所额外学到的特征并不是在validation集中的特征，因此对最后的结果没有显著的提升。

以上是关于对抗策略的尝试，然后基于这个猜想我想试图用分类策略来解决。

### 尝试了分类策略

针对Adversarial的问题和一个可能的猜想，我想试图用分类策略来进行改进。

我的初步想法是想设计一个分类器，然后这个分类器可以对数据集进行分类。假设有标注的数据集被这个分类器分类为$(A_1,A_2,...,A_n)$类，然后无标注的数据集的分类结果是$(A_{i1},A_{i2},A_{i3})$类，我们可以看这两个数据集有没有什么类重合了，然后用这个重合的类去参与对抗训练，这样可以试图精准地提升结果。这样就把对抗策略与训练策略的特征空间概率分布不一致的问题给部分解决了。

然后我设计的分类器是基于自动编码器来进行的。基本构造如下所示：

![1523945090793](C:\Users\Jiazhe Love Junjun\Desktop\Research-Recording-Documents\讨论\encoder)

自动编码器的基本思想是将输入降维到某一个向量，然后还原为图像尺寸大小的输出，要求输入与输出尽量相似。得到自动编码器的向量以后我根据2017年NIPS关于子空间聚类的论文设计了一个矩阵C，这个矩阵是一个对角元为0的矩阵，它的核心思想是把任意一个向量用其它的特征向量来线性表出，从而得到N个数据之间的关系，然后利用矩阵C进行谱聚类从而达到聚类特征。
$$
Z'=ZC
$$
为了方便训练，我利用语义分割网络所使用的Densenet结构来作为Encoder部分，这个策略是为了让自动编码器所提取的特征与语义分割所提取的特征尽量接近。我训练了自动编码器，结果如图所示：

![1523946351421](C:\Users\Jiazhe Love Junjun\Desktop\Research-Recording-Documents\讨论\encoder_result)

这个编码器学到了结节特征，然后起到了滤波的结果。

因为研究的**特征聚类算法与推荐标注策略**同样需要聚类结果，因此我得到编码器结果后顺便对这个策略进行了尝试，得到了一些好的结果与不好的结果，如下文所示。

我对传统聚类方法与子空间聚类方法都进行了比较，结果是这样的：

* 传统聚类方法

  我用自动编码器对每一张图片进行编码，得到了$N*100$的特征矩阵，对它进行聚类。

  1.  K-Means

     我尝试采用K-means进行聚类，但是聚类出来的图片很像是随机聚类的。我从每一类里按比例随机选一部分数据组成新的训练数据集，训练数据集的数目为原训练集的一半，用这个数据集进行训练所得到的结果为直接从原训练集随机挑一半得到的结果一样，说明K-Means的聚类效果非常不好，并没有得到典型特征。结合K-Means只能进行凸聚类的特点，以及只能对欧式距离收敛的特征，我觉得我的特征空间分布可能不是凸的，以及对于距离的度量要采用其它方式。

  * 密度聚类

    密度聚类是一个比较有解释性的办法。

    我用密度聚类的方法，选取了cosine距离作为度量，并选取了$\epsilon,min-sample$这两个超参数。密度聚类会把输入数据分为孤立点类与其它类，孤立点是指在它周围$\epsilon$范围内的点小于$min-sample$，并且它不在任意一个核心点的$\epsilon$领域内。对于我的输入，聚类结果一般会把它分为5类，其中包括220个左右的孤立数据点，800个左右的第1类，以及其它3类。我的选取策略为尽量把孤立点类包含进来，然后在其它类中按比例选取。比如有一次分类结果是:

    ```python
    [270, 651, 10, 6, 6, 14]
    ```

    选择200个数据点作为训练集，我按照这个原则选取的结果是

    ```python
    [142, 40,5,3,3,7]
    ```

    密度聚类的策略起到了不错的效果。

    在取原训练集50%的数据时，在肺结节这个实例上密度聚类能够达到用原数据一样的结果，但是有一些随机选的策略也能达到。

    在取原训练集30%的数据时，密度聚类能够达到$Dice:0.75$的平均值

    在取原训练集20%的数据时，密度聚类比随机选策略有显著优越性。

    随机选策略在test与val的平均dice为$0.715,0.697$，而密度聚类策略为$0.741,0.725$，密度聚类确实起到了很好的效果。

* 特征子空间聚类法

  因为密度聚类法比较依赖于聚类超参数选择，聚类结果有点不均衡，而且思想很简单，所以我觉得可能得出比较好的结果有点依赖于自动编码器的结果比较好，因此我对特征子空间聚类也进行了尝试。原论文的思想是用最小化loss函数计算关系矩阵C：
  $$
  L(\Theta,C)=1/2||X-\hat{X}_{\Theta}||^2_F+\lambda_1||C||_P+\lambda_2/2||Z_{\Theta_c}-Z_{\Theta_c}C||+\lambda_3*sum(diag(C)^2)
  $$
  这要求网络的输入是Batch Size为整个数据集图片个数，因此较深的编码器用不了。我采用了微调的策略，即仅在原自动编码器的子网络部分用损失函数进行训练：

  ![1523952765309](C:\Users\Jiazhe Love Junjun\Desktop\Research-Recording-Documents\讨论\subencoder)

  我训练这个子网络，最后用C来进行谱聚类，并在每类按比例随机选取一些数据用于训练。但是最后的结果非常差，最后结果和随机筛选的结果是一样的。然后我直接训练$Z'=ZC,diag(C)=0$这个更小部分，用C来进行谱聚类的结果仍然非常差。这个方法的原理非常具有可解释性，但是在我的这个实例问题上似乎并没有表现的很好，这也是一个科研困境。

其它对于用分类结果来进行精准对抗训练的想法我还未来得及尝试，以上就是我最近所做的一些东西和科研问题。







​h